{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Data processing","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\nimport numpy as np\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport sys\noldsysstdout = sys.stdout\nclass flushfile():\n    def __init__(self, f):\n        self.f = f\n    def __getattr__(self,name): \n        return object.__getattribute__(self.f, name)\n    def write(self, x):\n        self.f.write(x)\n        self.f.flush()\n    def flush(self):\n        self.f.flush()\nsys.stdout = flushfile(sys.stdout)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T06:21:09.875886Z","iopub.execute_input":"2021-09-29T06:21:09.876244Z","iopub.status.idle":"2021-09-29T06:21:10.059359Z","shell.execute_reply.started":"2021-09-29T06:21:09.876182Z","shell.execute_reply":"2021-09-29T06:21:10.058532Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Train data","metadata":{}},{"cell_type":"code","source":"index_columns = [\"Unit\", \"Cycle\"]\nsettings_columns = [\"setting\" + str(i + 1) for i in range(3)]\nsensor_columns = [\"s\" + str(i + 1) for i in range(21)]\nfinal_columns = index_columns + settings_columns + sensor_columns\nengine_data = pd.read_csv(\"../input/cmapass/train_FD001.txt\", header=None, sep=\" \")\nengine_data = engine_data[engine_data.columns[0:26]]\nengine_data.columns = final_columns\n\nengine_data","metadata":{"execution":{"iopub.status.busy":"2021-09-29T06:21:10.060749Z","iopub.execute_input":"2021-09-29T06:21:10.061571Z","iopub.status.idle":"2021-09-29T06:21:10.396650Z","shell.execute_reply.started":"2021-09-29T06:21:10.061532Z","shell.execute_reply":"2021-09-29T06:21:10.395402Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\n\nengine_data.copy(deep=True).drop(['Unit'], axis=1).describe()\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-09-29T06:21:10.398616Z","iopub.execute_input":"2021-09-29T06:21:10.398867Z","iopub.status.idle":"2021-09-29T06:21:10.509521Z","shell.execute_reply.started":"2021-09-29T06:21:10.398841Z","shell.execute_reply":"2021-09-29T06:21:10.508301Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\n\nengine_data.copy(deep=True).drop(['Unit'], axis=1).hist()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T06:21:10.512191Z","iopub.execute_input":"2021-09-29T06:21:10.512719Z","iopub.status.idle":"2021-09-29T06:21:15.251462Z","shell.execute_reply.started":"2021-09-29T06:21:10.512681Z","shell.execute_reply":"2021-09-29T06:21:15.250496Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Test data","metadata":{}},{"cell_type":"code","source":"engine_data_test = pd.read_csv(\"../input/cmapass/test_FD001.txt\", header=None, sep=\" \")\nengine_data_test = engine_data_test[engine_data_test.columns[0:26]]\nengine_data_test.columns = final_columns\n\nengine_data_test","metadata":{"execution":{"iopub.status.busy":"2021-09-29T06:21:15.252697Z","iopub.execute_input":"2021-09-29T06:21:15.252920Z","iopub.status.idle":"2021-09-29T06:21:15.397627Z","shell.execute_reply.started":"2021-09-29T06:21:15.252894Z","shell.execute_reply":"2021-09-29T06:21:15.396774Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"engine_data[engine_data['Unit'] == 1].head()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T06:21:15.399057Z","iopub.execute_input":"2021-09-29T06:21:15.399527Z","iopub.status.idle":"2021-09-29T06:21:15.429604Z","shell.execute_reply.started":"2021-09-29T06:21:15.399487Z","shell.execute_reply":"2021-09-29T06:21:15.428764Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"engine_data[engine_data['Unit'] == 1].tail()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T06:21:15.430811Z","iopub.execute_input":"2021-09-29T06:21:15.431158Z","iopub.status.idle":"2021-09-29T06:21:15.458660Z","shell.execute_reply.started":"2021-09-29T06:21:15.431118Z","shell.execute_reply":"2021-09-29T06:21:15.458099Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\n\ndef get_RUL(engine_data):\n    \n    last_cycle = engine_data.groupby(['Unit'])[\"Cycle\"].max().reset_index()\n    \n   \n    final = pd.merge(engine_data, last_cycle, how=\"inner\", on=[\"Unit\"])\n    \n   \n    engine_data[\"RUL\"] = final[\"Cycle_y\"] - final[\"Cycle_x\"]\n    \n   \n    engine_data[\"binary_class\"] = engine_data[\"RUL\"].map(lambda x: 1 if x <= 30 else 0)\n    \n    \n    engine_data[\"multi_class\"] = engine_data[\"RUL\"].map(lambda x: 2 if x <= 15 else 1 if x<= 30 else 0)\n    return engine_data\n\ntrain_labels = get_RUL(engine_data.copy(deep=True))\nRUL_train = train_labels[\"RUL\"]\nbinary_class_train = train_labels[\"binary_class\"]\nmulti_class_train = train_labels[\"multi_class\"]\n\ntrain_labels","metadata":{"execution":{"iopub.status.busy":"2021-09-29T06:21:15.459618Z","iopub.execute_input":"2021-09-29T06:21:15.460286Z","iopub.status.idle":"2021-09-29T06:21:15.559468Z","shell.execute_reply.started":"2021-09-29T06:21:15.460249Z","shell.execute_reply":"2021-09-29T06:21:15.558605Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\nremaining_RUL_test = pd.read_csv(\"../input/cmapass/RUL_FD001.txt\", header=None)\nremaining_RUL_test[\"Unit\"] = remaining_RUL_test.index + 1\n\n\ndef get_RUL_test(engine_data_test, remaining_RUL_test):\n    \n    last_cycle = engine_data_test.copy(deep=True).groupby(['Unit'])[\"Cycle\"].max().reset_index()\n    \n  \n    final = pd.merge(last_cycle, engine_data_test.copy(deep=True), how=\"inner\", on=[\"Unit\", \"Cycle\"])\n    final = pd.merge(final, remaining_RUL_test, how=\"inner\", on=[\"Unit\"])\n    final[\"RUL\"] = final[0]\n  \n    final[\"binary_class\"] = final[\"RUL\"].map(lambda x: 1 if x <= 30 else 0)\n   \n    final[\"multi_class\"] = final[\"RUL\"].map(lambda x: 2 if x <= 15 else 1 if x<= 30 else 0)\n    return final\n\ntest_labels = get_RUL_test(engine_data_test.copy(deep=True), remaining_RUL_test)\nRUL_test = test_labels[\"RUL\"]\nbinary_class_test = test_labels[\"binary_class\"]\nmulti_class_test = test_labels[\"multi_class\"]\n\ntest_labels","metadata":{"execution":{"iopub.status.busy":"2021-09-29T06:21:15.560568Z","iopub.execute_input":"2021-09-29T06:21:15.560796Z","iopub.status.idle":"2021-09-29T06:21:15.632580Z","shell.execute_reply.started":"2021-09-29T06:21:15.560763Z","shell.execute_reply":"2021-09-29T06:21:15.631588Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Visualization","metadata":{}},{"cell_type":"code","source":"\ntarget_value = ['RUL']\nplot_data = engine_data.copy(deep=True)\nplot_data[\"RUL\"] = RUL_train\nfor i in range(24):\n    graph = sns.pairplot(plot_data[plot_data[\"Unit\"] <= 15], x_vars=target_value, \n                         y_vars=(sensor_columns + settings_columns)[i], hue=\"Unit\", size=3, aspect=2.5)\n    graph = graph.map(plt.scatter)\n    graph = graph.set(xlim=(300,0))\n    graph = graph.add_legend()","metadata":{"execution":{"iopub.status.busy":"2021-09-29T06:21:15.635927Z","iopub.execute_input":"2021-09-29T06:21:15.636578Z","iopub.status.idle":"2021-09-29T06:22:03.080183Z","shell.execute_reply.started":"2021-09-29T06:21:15.636543Z","shell.execute_reply":"2021-09-29T06:22:03.079189Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Feature Transformation","metadata":{}},{"cell_type":"code","source":"\n\nfrom sklearn.preprocessing import normalize\nfrom sklearn.decomposition import PCA\n\n\nfeatures_dropped = ['Unit', 'setting1', 'setting2', 'setting3', 's1', 's5', 's10', 's16', 's18', 's19']\n\nnormalized_data = engine_data.copy(deep=True).drop(features_dropped, axis=1)\n\nnormalized_data = np.log(normalized_data)\n\nn_components = 13\n\n\npca = PCA(n_components=n_components)\nreduced_data = pca.fit_transform(normalized_data)\nreduced_data = pd.DataFrame(reduced_data, columns=['Dimension ' + str(i+1) for i in range(n_components)])\n\nvariance = pd.DataFrame(pca.explained_variance_ratio_)\nprint(np.cumsum(pca.explained_variance_ratio_))\n\n\nlast_cycle = engine_data_test.copy(deep=True).groupby(['Unit'])[\"Cycle\"].max().reset_index()\nnormalized_data_test = engine_data_test.copy(deep=True)\nnormalized_data_test = pd.merge(last_cycle, normalized_data_test, how=\"inner\", on=[\"Unit\", \"Cycle\"])\nnormalized_data_test = normalized_data_test.drop(features_dropped, axis=1)\n\nnormalized_data_test = np.log(normalized_data_test)\n\n\nreduced_data_test = pca.transform(normalized_data_test)\nreduced_data_test = pd.DataFrame(reduced_data_test, columns=['Dimension ' + str(i+1) for i in range(n_components)])\nprint(reduced_data)\nprint(reduced_data_test)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T06:22:03.081646Z","iopub.execute_input":"2021-09-29T06:22:03.081959Z","iopub.status.idle":"2021-09-29T06:22:03.192019Z","shell.execute_reply.started":"2021-09-29T06:22:03.081920Z","shell.execute_reply":"2021-09-29T06:22:03.191197Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Train and evaluate the model","metadata":{}},{"cell_type":"markdown","source":"### Predict RUL using Regression","metadata":{}},{"cell_type":"code","source":"# RUL Model selection (Regression)\n\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.linear_model import LinearRegression, Ridge, BayesianRidge, HuberRegressor, Lasso\nfrom sklearn.metrics import make_scorer, mean_squared_error\nfrom sklearn.ensemble import BaggingRegressor, RandomForestRegressor, AdaBoostRegressor\nfrom sklearn.svm import SVR  \nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n\n\ndef analyse_regression_models(train, labels):\n    results = {}\n    \n    def test_model(clf):\n        cv = KFold(n_splits=2, shuffle=True, random_state=20)\n        mse = make_scorer(mean_squared_error)\n        mse_val_score = cross_val_score(clf, train, labels, cv=cv, scoring=mse)\n        scores = [mse_val_score.mean()]\n        return scores\n    \n    clf = LinearRegression()\n    results[\"Linear\"] = test_model(clf)\n    \n    clf = Ridge()\n    results[\"Ridge\"] = test_model(clf)\n    \n    clf = BayesianRidge()\n    results[\"BayesianRidge\"] = test_model(clf)\n    \n    clf = HuberRegressor()\n    results[\"Huber\"] = test_model(clf)\n    \n    clf = Lasso()\n    results[\"Lasso\"] = test_model(clf)\n    \n    clf = MLPRegressor()\n    results[\"Neural Network\"] = test_model(clf)\n    \n    clf = BaggingRegressor()\n    results[\"Bagging\"] = test_model(clf)\n    \n    clf = RandomForestRegressor()\n    results[\"RandomForest\"] = test_model(clf)\n    \n    clf = AdaBoostRegressor()\n    results[\"AdaBoost\"] = test_model(clf)\n    \n    clf = SVR()\n    results[\"SVM\"] = test_model(clf)\n    \n    results = pd.DataFrame.from_dict(results, orient='index')\n    results.columns = [\"Mean Squared Error\"] \n    results = results.sort_values(by=[\"Mean Squared Error\"], ascending=True)\n    results.plot(kind=\"bar\", title=\"Model Scores\")\n    axes = plt.gca()\n    axes.set_ylim([800, 2500])\n    return results\n\nanalyse_regression_models(reduced_data, RUL_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T06:22:03.193576Z","iopub.execute_input":"2021-09-29T06:22:03.194044Z","iopub.status.idle":"2021-09-29T06:23:25.202317Z","shell.execute_reply.started":"2021-09-29T06:22:03.194001Z","shell.execute_reply":"2021-09-29T06:23:25.201507Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\n\nfrom sklearn.metrics import mean_squared_error, make_scorer, mean_absolute_error\nfrom sklearn.model_selection import KFold, GridSearchCV\nfrom sklearn.neural_network import MLPRegressor\n\ncv = KFold(n_splits=2, shuffle=True, random_state=20)\n\n\nparameters = {\n    'hidden_layer_sizes': [105],\n    'activation': ['logistic', 'relu'],\n    'solver': ['sgd'],\n    'learning_rate': ['constant', 'adaptive'],\n    'learning_rate_init': [0.001],\n    'momentum': [0.95],\n    'batch_size': [100]\n}\n\n\nclf = MLPRegressor(random_state=20)\nmse = make_scorer(mean_squared_error)\n\n\ngrid_obj = GridSearchCV(clf, parameters, cv=cv, scoring=mse)\n\n\ngrid_fit = grid_obj.fit(reduced_data, RUL_train)\n\n\nbest_clf = grid_fit.best_estimator_ \nprint(best_clf)\n\nbest_clf.fit(reduced_data, RUL_train)\n\nRUL_predictions = best_clf.predict(reduced_data_test)\n\nprint(\"Mean Absolute error: \" + str(mean_absolute_error(RUL_predictions, RUL_test)))\nprint(\"Mean Squared error: \" + str(mean_squared_error(RUL_predictions, RUL_test)))\n\n\nplt.scatter(RUL_test, RUL_predictions)\n\nstraight_line = np.arange(0, 400)\nplt.plot(straight_line, straight_line)\nplt.title(\"Fitted Values\")\nprint(RUL_predictions)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T06:23:25.204017Z","iopub.execute_input":"2021-09-29T06:23:25.204552Z","iopub.status.idle":"2021-09-29T06:26:35.923483Z","shell.execute_reply.started":"2021-09-29T06:23:25.204505Z","shell.execute_reply":"2021-09-29T06:26:35.922824Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Predict if an engine will fail within x1 cycles using Binary Classification\n\nValue of x1 is 30 in this case","metadata":{}},{"cell_type":"code","source":"\n\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\n\n\ndef analyse_binary_classification_models(train, labels):\n    results = {}\n    \n    def test_model(clf):\n        cv = KFold(n_splits=2, shuffle=True, random_state=20)\n        accuracy = make_scorer(accuracy_score)\n        accuracy_val_score = cross_val_score(clf, train, labels, cv=cv, scoring=accuracy)\n        scores = [accuracy_val_score.mean()]\n        return scores\n    \n    clf = KNeighborsClassifier(3)\n    print(\"KNeighbors\")\n    results[\"KNeighbors\"] = test_model(clf)\n    \n    clf = SVC()\n    print(\"SVC\")\n    results[\"SVM\"] = test_model(clf)\n    \n    clf = GaussianProcessClassifier()\n    print(\"GaussianProcess\")\n    results[\"GaussianProcess\"] = test_model(clf)\n    \n    clf = GaussianNB()\n    print(\"GaussianNB\")\n    results[\"GaussianNB\"] = test_model(clf)\n    \n    clf = QuadraticDiscriminantAnalysis()\n    print(\"QuadraticDiscriminantAnalysis\")\n    results[\"QuadraticDiscriminantAnalysis\"] = test_model(clf)\n    \n    clf = MLPClassifier(alpha=1)\n    print(\"Neural Network\")\n    results[\"Neural Network\"] = test_model(clf)\n    \n    clf = AdaBoostClassifier()\n    print(\"AdaBoost\")\n    results[\"AdaBoost\"] = test_model(clf)\n    \n    clf = DecisionTreeClassifier(max_depth=5)\n    print(\"Decision Tree\")\n    results[\"Decision Tree\"] = test_model(clf)\n    \n    clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n    print(\"RandomForest\")\n    results[\"RandomForest\"] = test_model(clf)\n    \n    results = pd.DataFrame.from_dict(results, orient='index')\n    results.columns = [\"Accuracy\"] \n    results = results.sort_values(by=[\"Accuracy\"], ascending=False)\n    results.plot(kind=\"bar\", title=\"Model Scores\")\n    axes = plt.gca()\n    axes.set_ylim([0, 1])\n    return results\n\nanalyse_binary_classification_models(reduced_data, binary_class_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T06:26:35.925038Z","iopub.execute_input":"2021-09-29T06:26:35.925489Z","iopub.status.idle":"2021-09-29T06:36:38.696718Z","shell.execute_reply.started":"2021-09-29T06:26:35.925458Z","shell.execute_reply":"2021-09-29T06:36:38.695877Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\n\nfrom sklearn.metrics import accuracy_score, make_scorer\nfrom sklearn.model_selection import KFold, GridSearchCV\nfrom sklearn.ensemble import AdaBoostClassifier\n\n\ncv = KFold(n_splits=2, shuffle=True, random_state=20)\n\n\nparameters = {\n    'learning_rate': [0.7, 1],\n    'algorithm': ['SAMME', 'SAMME.R'],\n    'n_estimators': [12, 25, 50, 100]\n}\n\n\nclf = AdaBoostClassifier(random_state=20)\n\naccuracy = make_scorer(accuracy_score)\n\n\ngrid_obj = GridSearchCV(clf, parameters, cv=cv, scoring=accuracy)\n\n\ngrid_fit = grid_obj.fit(reduced_data, binary_class_train)\n\n\nbest_clf = grid_fit.best_estimator_ \nprint(best_clf)\n\nbest_clf.fit(reduced_data, binary_class_train)\n\nbinary_class_predictions = best_clf.predict(reduced_data_test)\n\nprint(\"Accuracy: \" + str(accuracy_score(binary_class_predictions, binary_class_test)))\nprint(binary_class_predictions)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-29T06:36:38.698327Z","iopub.execute_input":"2021-09-29T06:36:38.698794Z","iopub.status.idle":"2021-09-29T06:37:23.768839Z","shell.execute_reply.started":"2021-09-29T06:36:38.698759Z","shell.execute_reply":"2021-09-29T06:37:23.767857Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Predict if an engine will fail in different time periods using Multi class classification \nIn this case, the 3 classes are RUL <=15, 15 < RUL <= 30 and RUL > 30","metadata":{}},{"cell_type":"code","source":"\n\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.multiclass import OneVsRestClassifier\n\n\n\ndef analyse_multiclass_classification_models(train, labels):\n    results = {}\n    \n    def test_model(clf):\n        clf = OneVsRestClassifier(clf)\n        cv = KFold(n_splits=2, shuffle=True, random_state=20)\n        accuracy = make_scorer(accuracy_score)\n        accuracy_val_score = cross_val_score(clf, train, labels, cv=cv, scoring=accuracy)\n        scores = [accuracy_val_score.mean()]\n        return scores\n    \n    clf = KNeighborsClassifier(3)\n    print(\"KNeighbors\")\n    results[\"KNeighbors\"] = test_model(clf)\n    \n    clf = SVC()\n    print(\"SVC\")\n    results[\"SVM\"] = test_model(clf)\n    \n    clf = GaussianProcessClassifier()\n    print(\"GaussianProcess\")\n    results[\"GaussianProcess\"] = test_model(clf)\n    \n    clf = GaussianNB()\n    print(\"GaussianNB\")\n    results[\"GaussianNB\"] = test_model(clf)\n    \n    clf = QuadraticDiscriminantAnalysis()\n    print(\"QuadraticDiscriminantAnalysis\")\n    results[\"QuadraticDiscriminantAnalysis\"] = test_model(clf)\n    \n    clf = MLPClassifier(alpha=1)\n    print(\"Neural Network\")\n    results[\"Neural Network\"] = test_model(clf)\n    \n    clf = AdaBoostClassifier()\n    print(\"AdaBoost\")\n    results[\"AdaBoost\"] = test_model(clf)\n    \n    clf = DecisionTreeClassifier(max_depth=5)\n    print(\"Decision Tree\")\n    results[\"Decision Tree\"] = test_model(clf)\n    \n    clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n    print(\"RandomForest\")\n    results[\"RandomForest\"] = test_model(clf)\n    \n    results = pd.DataFrame.from_dict(results, orient='index')\n    results.columns = [\"Accuracy\"] \n    results = results.sort_values(by=[\"Accuracy\"], ascending=False)\n    results.plot(kind=\"bar\", title=\"Model Scores\")\n    axes = plt.gca()\n    axes.set_ylim([0, 1])\n    return results\n\nanalyse_multiclass_classification_models(reduced_data, multi_class_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T06:37:23.770614Z","iopub.execute_input":"2021-09-29T06:37:23.770915Z","iopub.status.idle":"2021-09-29T07:13:14.126716Z","shell.execute_reply.started":"2021-09-29T06:37:23.770875Z","shell.execute_reply":"2021-09-29T07:13:14.125087Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\n\nfrom sklearn.metrics import accuracy_score, make_scorer\nfrom sklearn.model_selection import KFold, GridSearchCV\nfrom sklearn.ensemble import AdaBoostClassifier\n\n\ncv = KFold(n_splits=2, shuffle=True, random_state=20)\n\nparameters = {\n    'learning_rate': [0.7, 1],\n    'algorithm': ['SAMME', 'SAMME.R'],\n    'n_estimators': [200, 50]\n}\n\n\nclf = AdaBoostClassifier(random_state=20)\n\naccuracy = make_scorer(accuracy_score)\n\n\ngrid_obj = GridSearchCV(clf, parameters, cv=cv, scoring=accuracy)\n\n\ngrid_fit = grid_obj.fit(reduced_data, multi_class_train)\n\n\nbest_clf = grid_fit.best_estimator_ \nbest_clf = OneVsRestClassifier(best_clf)\nprint(best_clf)\n\nbest_clf.fit(reduced_data, multi_class_train)\n\nmulti_class_predictions = best_clf.predict(reduced_data_test)\n\nprint(\"Accuracy: \" + str(accuracy_score(multi_class_predictions, multi_class_test)))\nprint(multi_class_predictions)","metadata":{"execution":{"iopub.status.busy":"2021-09-29T07:13:14.130690Z","iopub.execute_input":"2021-09-29T07:13:14.131040Z","iopub.status.idle":"2021-09-29T07:14:36.014387Z","shell.execute_reply.started":"2021-09-29T07:13:14.130992Z","shell.execute_reply":"2021-09-29T07:14:36.013537Z"},"trusted":true},"execution_count":18,"outputs":[]}]}